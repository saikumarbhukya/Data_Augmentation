{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db8a800f",
   "metadata": {},
   "source": [
    "# Importing dependencies\n",
    "**Pip, in case of no Module errors**\n",
    "\n",
    "*Note: If you are using collab, this might not work, do it in your local machine*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04315203",
   "metadata": {},
   "source": [
    "**If you are making dataset from internet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bing-image-downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c97fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bing_image_downloader import downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59181cf1",
   "metadata": {},
   "source": [
    "**If you are making dataset from your own camera**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455607c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import labelme\n",
    "# if you want to name your captured images with unique id's you could use uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baedfcd",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d215af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "num_Img = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423813d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making data folders\n",
    "if os.path.exists(data_dir):\n",
    "    if os.path.exists(os.path.join(data_dir,'image')):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(os.path.join(data_dir,'image'))\n",
    "        \n",
    "    if os.path.exists(os.path.join(data_dir,'label')):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(os.path.join(data_dir,'label'))\n",
    "else:\n",
    "    os.mkdir(os.path.join(data_dir))\n",
    "    os.mkdir(os.path.join(data_dir,'image'))\n",
    "    os.mkdir(os.path.join(data_dir,'label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76dfaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for img_Num in range(num_Img):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imwrite(os.path.join(data_dir,'image','cap_img_{}.jpg'.format(img_Num)), frame)\n",
    "    cv2.imshow('image',frame)\n",
    "    time.sleep(5)\n",
    "    if cv2.waitKey(10) and 0xFF == 'q':\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d640db",
   "metadata": {},
   "source": [
    "**Load images fom bing search engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = os.path.join(data_dir,'image')\n",
    "downloader.download('People', limit = 50, output_dir = img_dir, adult_filter_off = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c3deb",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e81f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "len(os.listdir(img_dir)), len(os.listdir(os.path.join(data_dir,'label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36027631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cba799",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_aug = A.Compose([A.RandomBrightness(p=0.5),\n",
    "                        A.RandomContrast(p=0.5),\n",
    "                        A.RandomGamma(p=0.2),\n",
    "                        A.RandomSunFlare(p=0.1),\n",
    "                        A.RandomGravel(p=0.1),\n",
    "                        A.RandomRain(p=0.3),\n",
    "                        A.RandomToneCurve(p=0.3),\n",
    "                        A.HorizontalFlip(p=0.5),\n",
    "                        A.VerticalFlip(p=0.5),\n",
    "                        A.RandomRotate90(p=0.3)],\n",
    "                       keypoint_params=A.KeypointParams(format='xy', label_fields=['class_labels']),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eb9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(data_dir,'image','cap_img_0.jpg'))\n",
    "with open(os.path.join(data_dir,'label','cap_img_0.json')) as f:\n",
    "    annot = json.load(f)\n",
    "    stuff = annot['shapes']\n",
    "    aug = sample_aug(image = img,\n",
    "                     keypoints = [tuple(stuff[0]['points'][0]),tuple(stuff[1]['points'][0])], \n",
    "                     class_labels=[stuff[0]['label'], stuff[1]['label']])\n",
    "    plt.imshow(cv2.cvtColor(aug['image'], cv2.COLOR_BGR2RGB))\n",
    "    print(aug['keypoints'],aug['class_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/heartexlabs/labelImg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyqt5 lxml labelimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af726f26",
   "metadata": {},
   "source": [
    "# Reading frames from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(\"C:\\Users\\raraj\\Downloads\\vlc-record-2023-07-03-15h56m40s-_101_SMOKE_NVR_ch76_main_20230702113100_20230702113303.dav-.mp4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e939cf",
   "metadata": {},
   "source": [
    "# Removing alternate images in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d136b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def remove_alternate(data_path):\n",
    "    init = 0\n",
    "    for i in os.listdir(data_path):\n",
    "        if init%2==0:\n",
    "            os.remove(os.path.join(data_path,i))\n",
    "        init+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b8641",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_alternate(os.path.join('c:\\\\','Users','raraj','Downloads','annotations','dataset2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c62d8",
   "metadata": {},
   "source": [
    "# Counting and Pointing out stabel objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d5875",
   "metadata": {},
   "source": [
    "## Reading text annotation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annot(label_path):\n",
    "    file = open(label_path, \"r\")\n",
    "    f = file.readlines()\n",
    "    info = {}\n",
    "    coord_li = []\n",
    "    for i in f:\n",
    "        li = i.split(' ')\n",
    "        label = int(li[0])\n",
    "        coords = list(map(float, li[1:]))\n",
    "        if label not in info:\n",
    "            info.update({label:[coords]})\n",
    "        else:\n",
    "            info[label].append(coords)\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_annot(label_path):\n",
    "    file = open(file_path, \"a\")\n",
    "    file.write('\\nmatter added  successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_txt(os.path.join(\"C:\\\\\",\"Users\",\"raraj\",\"Downloads\",\"annotations\",\"dataset2\",\"exp.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d31225",
   "metadata": {},
   "source": [
    "# Object detection data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40e3d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622d0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/annotations/failed\"\n",
    "#os.path.join('c:\\\\','Users','raraj','Downloads','annotations','open_source')\n",
    "new_path = \"D:/annotations/Fire_Zawar_mines/Augmented\"\n",
    "#os.path.join('c:\\\\','Users','raraj','Downloads','annotations','Flipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b4ffb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = A.Compose([A.augmentations.geometric.transforms.Affine(p=0.3,scale=[0.25,1.75]),\n",
    "                 A.augmentations.geometric.transforms.Affine(p=0.2,rotate=[-45,45])],\n",
    "                bbox_params=A.BboxParams(format='yolo'))\n",
    "aug2 = A.Compose([A.HorizontalFlip(p=1)],\n",
    "                 bbox_params=A.BboxParams(format='yolo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f268546",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "c=0\n",
    "for i in os.listdir(data_path):\n",
    "    annot=[]\n",
    "    # getting the image\n",
    "    if i.split('.')[1]=='jpg':\n",
    "        label=os.path.join(data_path,f'{i.split(\".\")[0]}.txt')\n",
    "        if os.path.exists(label):\n",
    "            with open(label,'r') as l:\n",
    "                labels = l.readlines()\n",
    "                img = cv2.imread(os.path.join(data_path,i))\n",
    "            for j in labels:\n",
    "                li = j.split(\" \")\n",
    "                label = int(li[0])\n",
    "                coord = list(map(float, li[1:]))\n",
    "                coord.append(label)\n",
    "                annot.append(coord)\n",
    "            try:\n",
    "                sample_aug = aug1(image=img, bboxes=annot)\n",
    "                flipped = aug2(image=img, bboxes=annot)\n",
    "                cv2.imwrite(os.path.join(new_path,f'{i.split(\".\")[0]}_afine_transform.jpg'),sample_aug['image'])\n",
    "                cv2.imwrite(os.path.join(new_path,f'{i.split(\".\")[0]}_flipped.jpg'),flipped['image'])\n",
    "                with open(os.path.join(new_path,f'{i.split(\".\")[0]}_afine_transform.txt'),'w') as new:\n",
    "                    for k in range(len(sample_aug['bboxes'])):\n",
    "                        new.write(f\"{sample_aug['bboxes'][k][-1]} {sample_aug['bboxes'][k][0]} {sample_aug['bboxes'][k][1]} {sample_aug['bboxes'][k][2]} {sample_aug['bboxes'][k][3]} \\n\")\n",
    "                new.close()\n",
    "                with open(os.path.join(new_path,f'{i.split(\".\")[0]}_flipped.txt'),'w') as flip:\n",
    "                    for k in range(len(flipped['bboxes'])):\n",
    "                        flip.write(f\"{flipped['bboxes'][k][-1]} {flipped['bboxes'][k][0]} {flipped['bboxes'][k][1]} {flipped['bboxes'][k][2]} {flipped['bboxes'][k][3]} \\n\")\n",
    "                flip.close()\n",
    "            except:\n",
    "                c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_aug.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19292c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f61f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_aug['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6baedd8",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4130ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def split_data(data_path,new_path,n_splits,annoted=False,annot_format=None):\n",
    "    if annoted:\n",
    "        assert annot_format!=None\n",
    "        data_list = os.listdir(data_path)\n",
    "        for _ in data_list:\n",
    "            if _.split(\".\")[1]==annot_format:\n",
    "                data_list.remove(_)\n",
    "        split_value = len(data_list)//n_splits\n",
    "    else:\n",
    "        data_list = os.listdir(data_path)\n",
    "        split_value = len(data_list)//n_splits\n",
    "    splitted_li = []\n",
    "    start_limit = 0\n",
    "    end_limit = split_value\n",
    "    for i in range(1,split_value+1):\n",
    "        try:\n",
    "            splitted_li.append(data_list[start_limit:end_limit])\n",
    "            start_limit = end_limit\n",
    "            end_limit = split_value*(i+1)\n",
    "        except IndexError:\n",
    "            splitted_li.append(data_list[start_limit:])\n",
    "    for n,j in enumerate(splitted_li):\n",
    "        cur_path = os.path.join(new_path,f'{n}')\n",
    "        for k in j:\n",
    "            if os.path.exists(cur_path):\n",
    "                os.replace(os.path.join(data_path,k),os.path.join(cur_path,k))\n",
    "            else:\n",
    "                os.mkdir(cur_path)\n",
    "                os.replace(os.path.join(data_path,k),os.path.join(cur_path,k))\n",
    "            if annoted:\n",
    "                if os.path.exists(os.path.join(data_path,f'{k.split(\".\")[0]}.{annot_format}')):\n",
    "                    os.replace(os.path.join(data_path,f'{k.split(\".\")[0]}.{annot_format}'),os.path.join(cur_path,f'{k.split(\".\")[0]}.{annot_format}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9cb32cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_path = 'D:/annotations/fire_comm'\n",
    "new_path = 'D:/annotations/fire_comm'\n",
    "split_data(data_path,new_path,3,True,'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4f6500d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jpg'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample=\"B27_2023-05-31_12-17-38.mp426477.jpg\"\n",
    "sample[::-1].split(\".\",1)[0][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7af7414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "json_path = \"C:/Users/raraj/Downloads/test.json\"\n",
    "json_file = open(json_path)\n",
    "type(json.load(json_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f448a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"\"\"{\n",
    "    \"Name\": \"Jennifer Smith\",\n",
    "    \"Contact Number\": 7867567898,\n",
    "    \"Email\": \"jen123@gmail.com\",\n",
    "    \"Hobbies\":[\"Reading\", \"Sketching\", \"Horse Riding\"]\n",
    "    }\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d06fc810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=json.loads(string)\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f2af5b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"2\"=4,\"3\"=6,\"4\"=\"?? ??\\\\\\\\?\"}'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z={(1,2):2,2:4,3:6,4:'?? ??\\?'}\n",
    "n=json.dumps(z, skipkeys=True, ensure_ascii=True, separators =(\",\", \"=\"))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a94cf",
   "metadata": {},
   "source": [
    "n = float('nan')\n",
    "print(type(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a1333fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "fmt = '%(asctime)s: %(message)s'\n",
    "logging.basicConfig(format=fmt, filename=\"C:/Users/raraj/test.log\", level=logging.INFO, filemode='a')\n",
    "logging.info('This will get logged')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf41891",
   "metadata": {},
   "source": [
    "# Keypoint data sugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9f53c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raraj\\Downloads\\annotations\\data\\image\\cap_img_0.jpg None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "image must be numpy array type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m60\u001b[39m):\n\u001b[0;32m     45\u001b[0m     annotation \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 46\u001b[0m     new_aug \u001b[38;5;241m=\u001b[39m \u001b[43maugmentor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkeypoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpoint_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     48\u001b[0m     annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mnew_aug[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\computer_vision\\ComVis\\lib\\site-packages\\albumentations\\core\\composition.py:195\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, force_apply, *args, **data)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to pass data to augmentations as named arguments, for example: aug(image=image)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_check_args:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_args(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(force_apply, (\u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mint\u001b[39m)), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_apply must have bool or int type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m need_to_run \u001b[38;5;241m=\u001b[39m force_apply \u001b[38;5;129;01mor\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp\n",
      "File \u001b[1;32m~\\computer_vision\\ComVis\\lib\\site-packages\\albumentations\\core\\composition.py:275\u001b[0m, in \u001b[0;36mCompose._check_args\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_data_name \u001b[38;5;129;01min\u001b[39;00m checked_single:\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m must be numpy array type\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data_name))\n\u001b[0;32m    276\u001b[0m     shapes\u001b[38;5;241m.\u001b[39mappend(data\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_data_name \u001b[38;5;129;01min\u001b[39;00m checked_multi:\n",
      "\u001b[1;31mTypeError\u001b[0m: image must be numpy array type"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on 15-May-2023\n",
    "\n",
    "@author: raraj\n",
    "'''\n",
    "import cv2\n",
    "import json\n",
    "import albumentations as A\n",
    "import os\n",
    "\n",
    "\n",
    "augmentor =    A.Compose([A.RandomBrightness(p=0.5),\n",
    "                    A.RandomContrast(p=0.5),\n",
    "                    A.RandomGamma(p=0.2),\n",
    "                    A.RandomFog(p=0.1),\n",
    "                    A.RandomRain(p=0.3),\n",
    "                    A.RandomToneCurve(p=0.3),\n",
    "                    A.HorizontalFlip(p=0.5),\n",
    "                    A.VerticalFlip(p=0.5),\n",
    "                    A.RandomRotate90(p=0.3),\n",
    "                    A.augmentations.geometric.transforms.Affine(p=0.3,scale=[0.25,0.75]),\n",
    "                    A.augmentations.geometric.transforms.Affine(p=0.3,scale=[1.25,1.75]),\n",
    "                    A.augmentations.geometric.transforms.Affine(p=0.3,rotate=[-15,15]) ],\n",
    "                   keypoint_params=A.KeypointParams(format='xy', label_fields=['point_labels','image_labels' ]),)\n",
    "\n",
    "label_dir = r\"C:\\Users\\raraj\\Downloads\\annotations\\data\\label\"\n",
    "labels = os.listdir(label_dir)\n",
    "root_dir = r\"C:\\Users\\raraj\\Downloads\\annotations\"\n",
    "for label in labels:\n",
    "    with open(os.path.join(label_dir,label)) as f:\n",
    "        annot = json.load(f)\n",
    "        stuff = annot['shapes']\n",
    "        img_path = os.path.join('/',root_dir,'data', 'image',f'{label.split(\".\")[0]}.jpg')\n",
    "        img = cv2.imread(img_path)\n",
    "        print(img_path, img)\n",
    "        if len(stuff)>2:\n",
    "            coords = [tuple(stuff[0]['points'][0]),tuple(stuff[1]['points'][0])]\n",
    "            classes = [stuff[0]['label'], stuff[1]['label']]\n",
    "            img_type = [stuff[2]['label']]\n",
    "        else:\n",
    "            coords = [tuple(stuff[0]['points'][0])]\n",
    "            classes = [stuff[0]['label']]\n",
    "            img_type = [stuff[1]['label']]\n",
    "        for i in range(60):\n",
    "            annotation = {}\n",
    "            new_aug = augmentor(image=img,keypoints=coords,point_labels=classes, image_labels = img_type)\n",
    "            annotation['image']=f'{img_path.split(\".\")[0]}_{i}.jpg'\n",
    "            annotation['points']=new_aug['keypoints']\n",
    "            annotation['point_labels']=new_aug['point_labels']\n",
    "            annotation['image_label']=new_aug['image_labels']\n",
    "            cv2.imwrite(f'{img_path.split(\".\")[0]}_{i}.jpg',new_aug['image'])\n",
    "            with open(os.path.join('/',root_dir,'data','label',f'{label.split(\".\")[0]}_{i}.json'), 'w') as o:\n",
    "                json.dump(annotation,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fe2f05d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/raraj/Downloads/annotations/data/image/cap_img_0.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(img)\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(1, \"C:/Users/raraj/Downloads/annotations/data/image/cap_img_0.jpg\")\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a736a",
   "metadata": {},
   "source": [
    "# Loggers\n",
    "**Check this out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df784f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(str(Path(__file__).parent.parent.parent))  # add utils/ to path\n",
    "from utils.datasets import LoadImagesAndLabels\n",
    "from utils.datasets import img2label_paths\n",
    "from utils.general import colorstr, xywh2xyxy, check_dataset\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    from wandb import init, finish\n",
    "except ImportError:\n",
    "    wandb = None\n",
    "\n",
    "WANDB_ARTIFACT_PREFIX = 'wandb-artifact://'\n",
    "\n",
    "\n",
    "def remove_prefix(from_string, prefix=WANDB_ARTIFACT_PREFIX):\n",
    "    return from_string[len(prefix):]\n",
    "\n",
    "\n",
    "def check_wandb_config_file(data_config_file):\n",
    "    wandb_config = '_wandb.'.join(data_config_file.rsplit('.', 1))  # updated data.yaml path\n",
    "    if Path(wandb_config).is_file():\n",
    "        return wandb_config\n",
    "    return data_config_file\n",
    "\n",
    "\n",
    "def get_run_info(run_path):\n",
    "    run_path = Path(remove_prefix(run_path, WANDB_ARTIFACT_PREFIX))\n",
    "    run_id = run_path.stem\n",
    "    project = run_path.parent.stem\n",
    "    model_artifact_name = 'run_' + run_id + '_model'\n",
    "    return run_id, project, model_artifact_name\n",
    "\n",
    "\n",
    "def check_wandb_resume(opt):\n",
    "    process_wandb_config_ddp_mode(opt) if opt.global_rank not in [-1, 0] else None\n",
    "    if isinstance(opt.resume, str):\n",
    "        if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):\n",
    "            if opt.global_rank not in [-1, 0]:  # For resuming DDP runs\n",
    "                run_id, project, model_artifact_name = get_run_info(opt.resume)\n",
    "                api = wandb.Api()\n",
    "                artifact = api.artifact(project + '/' + model_artifact_name + ':latest')\n",
    "                modeldir = artifact.download()\n",
    "                opt.weights = str(Path(modeldir) / \"last.pt\")\n",
    "            return True\n",
    "    return None\n",
    "\n",
    "\n",
    "def process_wandb_config_ddp_mode(opt):\n",
    "    with open(opt.data) as f:\n",
    "        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n",
    "    train_dir, val_dir = None, None\n",
    "    if isinstance(data_dict['train'], str) and data_dict['train'].startswith(WANDB_ARTIFACT_PREFIX):\n",
    "        api = wandb.Api()\n",
    "        train_artifact = api.artifact(remove_prefix(data_dict['train']) + ':' + opt.artifact_alias)\n",
    "        train_dir = train_artifact.download()\n",
    "        train_path = Path(train_dir) / 'data/images/'\n",
    "        data_dict['train'] = str(train_path)\n",
    "\n",
    "    if isinstance(data_dict['val'], str) and data_dict['val'].startswith(WANDB_ARTIFACT_PREFIX):\n",
    "        api = wandb.Api()\n",
    "        val_artifact = api.artifact(remove_prefix(data_dict['val']) + ':' + opt.artifact_alias)\n",
    "        val_dir = val_artifact.download()\n",
    "        val_path = Path(val_dir) / 'data/images/'\n",
    "        data_dict['val'] = str(val_path)\n",
    "    if train_dir or val_dir:\n",
    "        ddp_data_path = str(Path(val_dir) / 'wandb_local_data.yaml')\n",
    "        with open(ddp_data_path, 'w') as f:\n",
    "            yaml.dump(data_dict, f)\n",
    "        opt.data = ddp_data_path\n",
    "\n",
    "\n",
    "class WandbLogger():\n",
    "    def __init__(self, opt, name, run_id, data_dict, job_type='Training'):\n",
    "        # Pre-training routine --\n",
    "        self.job_type = job_type\n",
    "        self.wandb, self.wandb_run, self.data_dict = wandb, None if not wandb else wandb.run, data_dict\n",
    "        # It's more elegant to stick to 1 wandb.init call, but useful config data is overwritten in the WandbLogger's wandb.init call\n",
    "        if isinstance(opt.resume, str):  # checks resume from artifact\n",
    "            if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):\n",
    "                run_id, project, model_artifact_name = get_run_info(opt.resume)\n",
    "                model_artifact_name = WANDB_ARTIFACT_PREFIX + model_artifact_name\n",
    "                assert wandb, 'install wandb to resume wandb runs'\n",
    "                # Resume wandb-artifact:// runs here| workaround for not overwriting wandb.config\n",
    "                self.wandb_run = wandb.init(id=run_id, project=project, resume='allow')\n",
    "                opt.resume = model_artifact_name\n",
    "        elif self.wandb:\n",
    "            self.wandb_run = wandb.init(config=opt,\n",
    "                                        resume=\"allow\",\n",
    "                                        project='YOLOR' if opt.project == 'runs/train' else Path(opt.project).stem,\n",
    "                                        name=name,\n",
    "                                        job_type=job_type,\n",
    "                                        id=run_id) if not wandb.run else wandb.run\n",
    "        if self.wandb_run:\n",
    "            if self.job_type == 'Training':\n",
    "                if not opt.resume:\n",
    "                    wandb_data_dict = self.check_and_upload_dataset(opt) if opt.upload_dataset else data_dict\n",
    "                    # Info useful for resuming from artifacts\n",
    "                    self.wandb_run.config.opt = vars(opt)\n",
    "                    self.wandb_run.config.data_dict = wandb_data_dict\n",
    "                self.data_dict = self.setup_training(opt, data_dict)\n",
    "            if self.job_type == 'Dataset Creation':\n",
    "                self.data_dict = self.check_and_upload_dataset(opt)\n",
    "        else:\n",
    "            prefix = colorstr('wandb: ')\n",
    "            print(f\"{prefix}Install Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\")\n",
    "\n",
    "    def check_and_upload_dataset(self, opt):\n",
    "        assert wandb, 'Install wandb to upload dataset'\n",
    "        check_dataset(self.data_dict)\n",
    "        config_path = self.log_dataset_artifact(opt.data,\n",
    "                                                opt.single_cls,\n",
    "                                                'YOLOR' if opt.project == 'runs/train' else Path(opt.project).stem)\n",
    "        print(\"Created dataset config file \", config_path)\n",
    "        with open(config_path) as f:\n",
    "            wandb_data_dict = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        return wandb_data_dict\n",
    "\n",
    "    def setup_training(self, opt, data_dict):\n",
    "        self.log_dict, self.current_epoch, self.log_imgs = {}, 0, 16  # Logging Constants\n",
    "        self.bbox_interval = opt.bbox_interval\n",
    "        if isinstance(opt.resume, str):\n",
    "            modeldir, _ = self.download_model_artifact(opt)\n",
    "            if modeldir:\n",
    "                self.weights = Path(modeldir) / \"last.pt\"\n",
    "                config = self.wandb_run.config\n",
    "                opt.weights, opt.save_period, opt.batch_size, opt.bbox_interval, opt.epochs, opt.hyp = str(\n",
    "                    self.weights), config.save_period, config.total_batch_size, config.bbox_interval, config.epochs, \\\n",
    "                                                                                                       config.opt['hyp']\n",
    "            data_dict = dict(self.wandb_run.config.data_dict)  # eliminates the need for config file to resume\n",
    "        if 'val_artifact' not in self.__dict__:  # If --upload_dataset is set, use the existing artifact, don't download\n",
    "            self.train_artifact_path, self.train_artifact = self.download_dataset_artifact(data_dict.get('train'),\n",
    "                                                                                           opt.artifact_alias)\n",
    "            self.val_artifact_path, self.val_artifact = self.download_dataset_artifact(data_dict.get('val'),\n",
    "                                                                                       opt.artifact_alias)\n",
    "            self.result_artifact, self.result_table, self.val_table, self.weights = None, None, None, None\n",
    "            if self.train_artifact_path is not None:\n",
    "                train_path = Path(self.train_artifact_path) / 'data/images/'\n",
    "                data_dict['train'] = str(train_path)\n",
    "            if self.val_artifact_path is not None:\n",
    "                val_path = Path(self.val_artifact_path) / 'data/images/'\n",
    "                data_dict['val'] = str(val_path)\n",
    "                self.val_table = self.val_artifact.get(\"val\")\n",
    "                self.map_val_table_path()\n",
    "        if self.val_artifact is not None:\n",
    "            self.result_artifact = wandb.Artifact(\"run_\" + wandb.run.id + \"_progress\", \"evaluation\")\n",
    "            self.result_table = wandb.Table([\"epoch\", \"id\", \"prediction\", \"avg_confidence\"])\n",
    "        if opt.bbox_interval == -1:\n",
    "            self.bbox_interval = opt.bbox_interval = (opt.epochs // 10) if opt.epochs > 10 else 1\n",
    "        return data_dict\n",
    "\n",
    "    def download_dataset_artifact(self, path, alias):\n",
    "        if isinstance(path, str) and path.startswith(WANDB_ARTIFACT_PREFIX):\n",
    "            dataset_artifact = wandb.use_artifact(remove_prefix(path, WANDB_ARTIFACT_PREFIX) + \":\" + alias)\n",
    "            assert dataset_artifact is not None, \"'Error: W&B dataset artifact doesn\\'t exist'\"\n",
    "            datadir = dataset_artifact.download()\n",
    "            return datadir, dataset_artifact\n",
    "        return None, None\n",
    "\n",
    "    def download_model_artifact(self, opt):\n",
    "        if opt.resume.startswith(WANDB_ARTIFACT_PREFIX):\n",
    "            model_artifact = wandb.use_artifact(remove_prefix(opt.resume, WANDB_ARTIFACT_PREFIX) + \":latest\")\n",
    "            assert model_artifact is not None, 'Error: W&B model artifact doesn\\'t exist'\n",
    "            modeldir = model_artifact.download()\n",
    "            epochs_trained = model_artifact.metadata.get('epochs_trained')\n",
    "            total_epochs = model_artifact.metadata.get('total_epochs')\n",
    "            assert epochs_trained < total_epochs, 'training to %g epochs is finished, nothing to resume.' % (\n",
    "                total_epochs)\n",
    "            return modeldir, model_artifact\n",
    "        return None, None\n",
    "\n",
    "    def log_model(self, path, opt, epoch, fitness_score, best_model=False):\n",
    "        model_artifact = wandb.Artifact('run_' + wandb.run.id + '_model', type='model', metadata={\n",
    "            'original_url': str(path),\n",
    "            'epochs_trained': epoch + 1,\n",
    "            'save period': opt.save_period,\n",
    "            'project': opt.project,\n",
    "            'total_epochs': opt.epochs,\n",
    "            'fitness_score': fitness_score\n",
    "        })\n",
    "        model_artifact.add_file(str(path / 'last.pt'), name='last.pt')\n",
    "        wandb.log_artifact(model_artifact,\n",
    "                           aliases=['latest', 'epoch ' + str(self.current_epoch), 'best' if best_model else ''])\n",
    "        print(\"Saving model artifact on epoch \", epoch + 1)\n",
    "\n",
    "    def log_dataset_artifact(self, data_file, single_cls, project, overwrite_config=False):\n",
    "        with open(data_file) as f:\n",
    "            data = yaml.load(f, Loader=yaml.SafeLoader)  # data dict\n",
    "        nc, names = (1, ['item']) if single_cls else (int(data['nc']), data['names'])\n",
    "        names = {k: v for k, v in enumerate(names)}  # to index dictionary\n",
    "        self.train_artifact = self.create_dataset_table(LoadImagesAndLabels(\n",
    "            data['train']), names, name='train') if data.get('train') else None\n",
    "        self.val_artifact = self.create_dataset_table(LoadImagesAndLabels(\n",
    "            data['val']), names, name='val') if data.get('val') else None\n",
    "        if data.get('train'):\n",
    "            data['train'] = WANDB_ARTIFACT_PREFIX + str(Path(project) / 'train')\n",
    "        if data.get('val'):\n",
    "            data['val'] = WANDB_ARTIFACT_PREFIX + str(Path(project) / 'val')\n",
    "        path = data_file if overwrite_config else '_wandb.'.join(data_file.rsplit('.', 1))  # updated data.yaml path\n",
    "        data.pop('download', None)\n",
    "        with open(path, 'w') as f:\n",
    "            yaml.dump(data, f)\n",
    "\n",
    "        if self.job_type == 'Training':  # builds correct artifact pipeline graph\n",
    "            self.wandb_run.use_artifact(self.val_artifact)\n",
    "            self.wandb_run.use_artifact(self.train_artifact)\n",
    "            self.val_artifact.wait()\n",
    "            self.val_table = self.val_artifact.get('val')\n",
    "            self.map_val_table_path()\n",
    "        else:\n",
    "            self.wandb_run.log_artifact(self.train_artifact)\n",
    "            self.wandb_run.log_artifact(self.val_artifact)\n",
    "        return path\n",
    "\n",
    "    def map_val_table_path(self):\n",
    "        self.val_table_map = {}\n",
    "        print(\"Mapping dataset\")\n",
    "        for i, data in enumerate(tqdm(self.val_table.data)):\n",
    "            self.val_table_map[data[3]] = data[0]\n",
    "\n",
    "    def create_dataset_table(self, dataset, class_to_id, name='dataset'):\n",
    "        # TODO: Explore multiprocessing to slpit this loop parallely| This is essential for speeding up the the logging\n",
    "        artifact = wandb.Artifact(name=name, type=\"dataset\")\n",
    "        img_files = tqdm([dataset.path]) if isinstance(dataset.path, str) and Path(dataset.path).is_dir() else None\n",
    "        img_files = tqdm(dataset.img_files) if not img_files else img_files\n",
    "        for img_file in img_files:\n",
    "            if Path(img_file).is_dir():\n",
    "                artifact.add_dir(img_file, name='data/images')\n",
    "                labels_path = 'labels'.join(dataset.path.rsplit('images', 1))\n",
    "                artifact.add_dir(labels_path, name='data/labels')\n",
    "            else:\n",
    "                artifact.add_file(img_file, name='data/images/' + Path(img_file).name)\n",
    "                label_file = Path(img2label_paths([img_file])[0])\n",
    "                artifact.add_file(str(label_file),\n",
    "                                  name='data/labels/' + label_file.name) if label_file.exists() else None\n",
    "        table = wandb.Table(columns=[\"id\", \"train_image\", \"Classes\", \"name\"])\n",
    "        class_set = wandb.Classes([{'id': id, 'name': name} for id, name in class_to_id.items()])\n",
    "        for si, (img, labels, paths, shapes) in enumerate(tqdm(dataset)):\n",
    "            height, width = shapes[0]\n",
    "            labels[:, 2:] = (xywh2xyxy(labels[:, 2:].view(-1, 4))) * torch.Tensor([width, height, width, height])\n",
    "            box_data, img_classes = [], {}\n",
    "            for cls, *xyxy in labels[:, 1:].tolist():\n",
    "                cls = int(cls)\n",
    "                box_data.append({\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
    "                                 \"class_id\": cls,\n",
    "                                 \"box_caption\": \"%s\" % (class_to_id[cls]),\n",
    "                                 \"scores\": {\"acc\": 1},\n",
    "                                 \"domain\": \"pixel\"})\n",
    "                img_classes[cls] = class_to_id[cls]\n",
    "            boxes = {\"ground_truth\": {\"box_data\": box_data, \"class_labels\": class_to_id}}  # inference-space\n",
    "            table.add_data(si, wandb.Image(paths, classes=class_set, boxes=boxes), json.dumps(img_classes),\n",
    "                           Path(paths).name)\n",
    "        artifact.add(table, name)\n",
    "        return artifact\n",
    "\n",
    "    def log_training_progress(self, predn, path, names):\n",
    "        if self.val_table and self.result_table:\n",
    "            class_set = wandb.Classes([{'id': id, 'name': name} for id, name in names.items()])\n",
    "            box_data = []\n",
    "            total_conf = 0\n",
    "            for *xyxy, conf, cls in predn.tolist():\n",
    "                if conf >= 0.25:\n",
    "                    box_data.append(\n",
    "                        {\"position\": {\"minX\": xyxy[0], \"minY\": xyxy[1], \"maxX\": xyxy[2], \"maxY\": xyxy[3]},\n",
    "                         \"class_id\": int(cls),\n",
    "                         \"box_caption\": \"%s %.3f\" % (names[cls], conf),\n",
    "                         \"scores\": {\"class_score\": conf},\n",
    "                         \"domain\": \"pixel\"})\n",
    "                    total_conf = total_conf + conf\n",
    "            boxes = {\"predictions\": {\"box_data\": box_data, \"class_labels\": names}}  # inference-space\n",
    "            id = self.val_table_map[Path(path).name]\n",
    "            self.result_table.add_data(self.current_epoch,\n",
    "                                       id,\n",
    "                                       wandb.Image(self.val_table.data[id][1], boxes=boxes, classes=class_set),\n",
    "                                       total_conf / max(1, len(box_data))\n",
    "                                       )\n",
    "\n",
    "    def log(self, log_dict):\n",
    "        if self.wandb_run:\n",
    "            for key, value in log_dict.items():\n",
    "                self.log_dict[key] = value\n",
    "\n",
    "    def end_epoch(self, best_result=False):\n",
    "        if self.wandb_run:\n",
    "            wandb.log(self.log_dict)\n",
    "            self.log_dict = {}\n",
    "            if self.result_artifact:\n",
    "                train_results = wandb.JoinedTable(self.val_table, self.result_table, \"id\")\n",
    "                self.result_artifact.add(train_results, 'result')\n",
    "                wandb.log_artifact(self.result_artifact, aliases=['latest', 'epoch ' + str(self.current_epoch),\n",
    "                                                                  ('best' if best_result else '')])\n",
    "                self.result_table = wandb.Table([\"epoch\", \"id\", \"prediction\", \"avg_confidence\"])\n",
    "                self.result_artifact = wandb.Artifact(\"run_\" + wandb.run.id + \"_progress\", \"evaluation\")\n",
    "\n",
    "    def finish_run(self):\n",
    "        if self.wandb_run:\n",
    "            if self.log_dict:\n",
    "                wandb.log(self.log_dict)\n",
    "            wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f81e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.wandb_logging.wandb_utils import WandbLogger, check_wandb_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47035256",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Logging- Doing this before checking the dataset. Might update data_dict\n",
    "    loggers = {'wandb': None}  # loggers dict\n",
    "    if rank in [-1, 0]:\n",
    "        opt.hyp = hyp  # add hyperparameters\n",
    "        run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
    "        wandb_logger = WandbLogger(opt, Path(opt.save_dir).stem, run_id, data_dict)\n",
    "        loggers['wandb'] = wandb_logger.wandb\n",
    "        data_dict = wandb_logger.data_dict\n",
    "        if wandb_logger.wandb:\n",
    "            weights, epochs, hyp = opt.weights, opt.epochs, opt.hyp  # WandbLogger might update weights, epochs if resuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "656a2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def sep_annot(data_path, new_path):\n",
    "    if os.path.exists(new_path):\n",
    "        for data in os.listdir(data_path):\n",
    "            if data.endswith(\".txt\") and os.path.exists(os.path.join(data_path,f'{data.split(\".\")[0]}.jpg')):\n",
    "                os.replace(os.path.join(data_path, data), os.path.join(data_path))\n",
    "                os.replace(os.path.join(data_path, f'{data.split(\".\")[0]}.jpg'), os.path.join(data_path))\n",
    "    else:\n",
    "        os.mkdir(new_path)\n",
    "        sep_annot(data_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec4f632e",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: 'C:/Users/raraj/Downloads/annotations/shoplifting_frames\\\\2988.txt' -> 'C:/Users/raraj/Downloads/annotations/shoplifting_frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msep_annot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/raraj/Downloads/annotations/shoplifting_frames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/raraj/Downloads/annotations/comleted_shoplifting_frames\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36msep_annot\u001b[1;34m(data_path, new_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_path):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m----> 7\u001b[0m             \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m             os\u001b[38;5;241m.\u001b[39mreplace(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: 'C:/Users/raraj/Downloads/annotations/shoplifting_frames\\\\2988.txt' -> 'C:/Users/raraj/Downloads/annotations/shoplifting_frames'"
     ]
    }
   ],
   "source": [
    "sep_annot(\"C:/Users/raraj/Downloads/annotations/shoplifting_frames\", \"C:/Users/raraj/Downloads/annotations/comleted_shoplifting_frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6730e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':'1', 'b':'2', 'c':'3', 'd':'4'}\n",
    "# list(map(lambda a.items() : a, a.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e79348e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda a: a+2, list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e48efbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['1', '2', '3', '4'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = a.values()\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae71d5b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1744704390.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[40], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    a.values() = list(map(lambda x: a[x]+'2', values))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "values = list(map(lambda x: a[x]+'2', values))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adde3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {\"shape_attributes\" : {\"name\": \"rect\", \"x\": 184, \"y\": 298, \"width\": 14, \"height\": 15}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7a631f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape_attributes': {'name': 'rect',\n",
       "  'x': 184,\n",
       "  'y': 298,\n",
       "  'width': 14,\n",
       "  'height': 15}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d485dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd5750e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'name': 'rect', 'x': 184, 'y': 298, 'width': 14, 'height': 15}])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d416485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysqlclient\n",
      "  Using cached mysqlclient-2.2.0-cp39-cp39-win_amd64.whl (200 kB)\n",
      "Installing collected packages: mysqlclient\n",
      "Successfully installed mysqlclient-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\raraj\\computer_vision\\ComVis\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install mysqlclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91e66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a131f4",
   "metadata": {},
   "source": [
    "# Data Preparation for action recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667acb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "draw = mp.solutions.drawing_utils\n",
    "holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054c0369",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy._DTypeMeta' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py:181\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbootstrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py:175\u001b[0m, in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: binary extension... OK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m submodule \u001b[38;5;129;01min\u001b[39;00m __collect_extra_submodules(DEBUG):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m__load_extra_py_code_for_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcv2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\__init__.py:28\u001b[0m, in \u001b[0;36m__load_extra_py_code_for_module\u001b[1;34m(base, name, enable_debug_print)\u001b[0m\n\u001b[0;32m     26\u001b[0m native_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(module_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m     py_module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m enable_debug_print:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\cv2\\typing\\__init__.py:69\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mNumpyVersion(numpy\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.20.0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m9\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m     NumPyArrayGeneric \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray[typing\u001b[38;5;241m.\u001b[39mAny, \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneric\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     NumPyArrayGeneric \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy._DTypeMeta' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_dirs(actions, samples_per_action, root_path, data_path):\n",
    "    for action in actions:\n",
    "        for sample in range(samples_per_action):\n",
    "            try:\n",
    "                os.makedirs(os.path.join(root_path, data_path, action, f\"{sample}\"))\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "\n",
    "def read_frames(data_path, frames_per_sample, source = 0):\n",
    "    if os.path.exists(data_path):\n",
    "        with holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as kp:\n",
    "            cap = cv2.VideoCapture(source)\n",
    "            for action in os.listdir(data_path):\n",
    "                for sample in os.listdir(os.path.join(data_path, action)):\n",
    "                    for frame_no in range(frames_per_sample):\n",
    "                        success, frame = cap.read()\n",
    "                        if success:\n",
    "                            result_kp = kp.process(frame)\n",
    "                            frame.flags.writeable = True\n",
    "                            draw.draw_landmarks(frame, result_kp.pose_landmarks, holistic.POSE_CONNECTIONS)\n",
    "                            if frame_no== 0:\n",
    "                                cv2.putText(frame, \"Started Collecting frames\", (120,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 4, cv2.LINE_AA)\n",
    "                                cv2.putText(frame, f\"Action: {action}\\nSample_no: {sample}\\nFrame_no: {frame_no}\", (120,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 4, cv2.LINE_AA)\n",
    "                            else:\n",
    "                                cv2.putText(frame, f\"Action: {action}\\nSample_no: {sample}\\nFrame_no: {frame_no}\", (120,200), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 4, cv2.LINE_AA)\n",
    "                            cv2.imshow(\"Source feed\", frame)\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        make_dirs([\"running\",\"sneaking\",\"hiding_item\",\"picking_item\"], 50, \"D:/annotations\", \"D:/annotations/Shoplifting_action_recognition\")\n",
    "        print(\"required directories created\\n starting to record the data\")\n",
    "        read_frames(data_path, frames_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4921a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_frames(\"D:/annotations/Shoplifting_action_recognition\", 50, source = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4712de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "absl-py                       1.2.0\n",
      "aiohttp                       3.8.1\n",
      "aiosignal                     1.2.0\n",
      "alabaster                     0.7.12\n",
      "albumentations                1.3.1\n",
      "anaconda-client               1.9.0\n",
      "anaconda-navigator            2.3.0\n",
      "anaconda-project              0.10.2Note: you may need to restart the kernel to use updated packages.\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "astroid                       2.6.6\n",
      "astropy                       5.0.4\n",
      "asttokens                     2.0.5\n",
      "astunparse                    1.6.3\n",
      "async-timeout                 4.0.1\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.4.1\n",
      "bkcharts                      0.2\n",
      "black                         19.10b0\n",
      "bleach                        4.1.0\n",
      "bokeh                         2.4.2\n",
      "boto3                         1.21.32\n",
      "botocore                      1.24.32\n",
      "Bottleneck                    1.3.4\n",
      "brotlipy                      0.7.0\n",
      "cachetools                    4.2.2\n",
      "certifi                       2021.10.8\n",
      "cffi                          1.15.0\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.4\n",
      "colorcet                      2.0.6\n",
      "comtypes                      1.1.10\n",
      "conda                         4.14.0\n",
      "conda-build                   3.21.8\n",
      "conda-content-trust           0+unknown\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        2.1.0\n",
      "conda_package_streaming       0.8.0\n",
      "conda-repo-cli                1.0.4\n",
      "conda-token                   0.3.0\n",
      "conda-verify                  3.4.2\n",
      "constantly                    15.1.0\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  3.4.8\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.28\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.5.0\n",
      "dask                          2022.2.1\n",
      "datashader                    0.13.0\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "distributed                   2022.2.1\n",
      "docutils                      0.17.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     0.8.3\n",
      "fastjsonschema                2.15.1\n",
      "filelock                      3.6.0\n",
      "flake8                        3.9.2\n",
      "Flask                         1.1.2\n",
      "flatbuffers                   2.0.7\n",
      "fonttools                     4.25.0\n",
      "frozenlist                    1.2.0\n",
      "fsspec                        2022.2.0\n",
      "future                        0.18.2\n",
      "gast                          0.4.0\n",
      "gensim                        4.1.2\n",
      "glob2                         0.7\n",
      "google-api-core               1.25.1\n",
      "google-auth                   1.33.0\n",
      "google-auth-oauthlib          0.4.6\n",
      "google-cloud-core             1.7.1\n",
      "google-cloud-storage          1.31.0\n",
      "google-crc32c                 1.1.2\n",
      "google-pasta                  0.2.0\n",
      "google-resumable-media        1.3.1\n",
      "googleapis-common-protos      1.53.0\n",
      "greenlet                      1.1.1\n",
      "grpcio                        1.42.0\n",
      "h5py                          3.6.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.14.8\n",
      "hvplot                        0.7.3\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.3\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.9.0\n",
      "imagesize                     1.3.0\n",
      "imgviz                        1.7.2\n",
      "importlib-metadata            4.11.3\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.9.1\n",
      "ipython                       8.2.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "Jinja2                        2.11.3\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.4.0\n",
      "jupyter                       1.0.0\n",
      "jupyter-client                6.1.12\n",
      "jupyter-console               6.4.0\n",
      "jupyter-core                  4.9.2\n",
      "jupyter-server                1.13.5\n",
      "jupyterlab                    3.3.2\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "keras                         2.10.0\n",
      "Keras-Preprocessing           1.1.2\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.3.2\n",
      "labelme                       5.2.1\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "libclang                      14.0.6\n",
      "llvmlite                      0.38.0\n",
      "locket                        0.2.1\n",
      "lxml                          4.8.0\n",
      "Markdown                      3.3.4\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.5.1\n",
      "matplotlib-inline             0.1.2\n",
      "mccabe                        0.6.1\n",
      "mediapipe                     0.10.5\n",
      "menuinst                      1.4.18\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.2\n",
      "multidict                     5.1.0\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               0.4.3\n",
      "mysql                         0.0.3\n",
      "mysqlclient                   2.2.0\n",
      "natsort                       8.4.0\n",
      "navigator-updater             0.2.1\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.4.4\n",
      "nbformat                      5.3.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.7.1\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.8\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.1\n",
      "numpy                         1.21.5\n",
      "numpydoc                      1.2\n",
      "oauthlib                      3.2.0\n",
      "olefile                       0.46\n",
      "opencv-contrib-python         4.6.0.66\n",
      "opencv-python                 4.6.0.66\n",
      "opencv-python-headless        4.7.0.72\n",
      "openpyxl                      3.0.9\n",
      "opt-einsum                    3.3.0\n",
      "packaging                     21.3\n",
      "pandas                        1.4.2\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.0\n",
      "param                         1.12.0\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathspec                      0.7.0\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "pika                          1.3.2\n",
      "Pillow                        9.0.1\n",
      "pip                           21.2.4\n",
      "pkginfo                       1.8.2\n",
      "plotly                        5.6.0\n",
      "pluggy                        1.0.0\n",
      "poyo                          0.5.0\n",
      "prometheus-client             0.13.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "protobuf                      3.20.3\n",
      "psutil                        5.8.0\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "py                            1.11.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.7.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.6\n",
      "pycurl                        7.44.1\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.3.1\n",
      "Pygments                      2.11.2\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.9.6\n",
      "pyls-spyder                   0.4.0\n",
      "PyNaCl                        1.4.0\n",
      "pyodbc                        4.0.32\n",
      "pyOpenSSL                     21.0.0\n",
      "pyparsing                     3.0.4\n",
      "PyQt5                         5.15.9\n",
      "PyQt5-Qt5                     5.15.2\n",
      "PyQt5-sip                     12.12.1\n",
      "pyreadline                    2.1\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.1\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.2.4\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "python-version                0.0.2\n",
      "pytz                          2021.3\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "pywin32                       302\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.2\n",
      "PyYAML                        6.0\n",
      "pyzmq                         22.3.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.3.0\n",
      "QtPy                          2.0.1\n",
      "qudida                        0.0.4\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.3.15\n",
      "requests                      2.27.1\n",
      "requests-file                 1.5.1\n",
      "requests-oauthlib             1.3.1\n",
      "rope                          0.22.0\n",
      "rsa                           4.7.2\n",
      "Rtree                         0.9.7\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.5.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20220215.102710\n",
      "scipy                         1.7.3\n",
      "Scrapy                        2.6.1\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    61.2.0\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    5.1.0\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "sounddevice                   0.4.6\n",
      "soupsieve                     2.3.1\n",
      "Sphinx                        4.4.0\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.1.5\n",
      "spyder-kernels                2.1.3\n",
      "SQLAlchemy                    1.4.32\n",
      "stack-data                    0.2.0\n",
      "statsmodels                   0.13.2\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.9\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.0.1\n",
      "tensorboard                   2.10.0\n",
      "tensorboard-data-server       0.6.1\n",
      "tensorboard-plugin-wit        1.8.1\n",
      "tensorflow                    2.10.0\n",
      "tensorflow-estimator          2.10.0\n",
      "tensorflow-io-gcs-filesystem  0.27.0\n",
      "termcolor                     1.1.0\n",
      "terminado                     0.13.1\n",
      "testpath                      0.5.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomli                         1.2.2\n",
      "toolz                         0.11.2\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.0\n",
      "traitlets                     5.1.1\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typed-ast                     1.4.3\n",
      "typing_extensions             4.1.1\n",
      "ujson                         5.1.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.9\n",
      "w3lib                         1.21.0\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "win-unicode-console           0.5\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.12.1\n",
      "xarray                        0.20.1\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.24.9\n",
      "yapf                          0.31.0\n",
      "yarl                          1.6.3\n",
      "zict                          2.0.0\n",
      "zipp                          3.7.0\n",
      "zope.interface                5.4.0\n",
      "zstandard                     0.19.0\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b7a721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\raraj\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\raraj\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "  Attempting uninstall: opencv-python\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raraj\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found existing installation: opencv-python 4.6.0.66\n",
      "    Uninstalling opencv-python-4.6.0.66:\n",
      "      Successfully uninstalled opencv-python-4.6.0.66\n",
      "Successfully installed opencv-python-4.8.0.76\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993ee2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb092a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
